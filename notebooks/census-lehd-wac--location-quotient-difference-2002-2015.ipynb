{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Census LEHD WAC Location Quotient Difference 2002 – 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the _Location Quotient_ difference of LEHD WAC data.  \n",
    "**Note:** lots of duplication in this notebook for the 2002 and 2015 LQ analysis that could be abstracted, which is what I ended up doing for the python script that is used to create the output data when running `make`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import sys, os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify paths for csv and shapefile data\n",
    "dirname = os.path.dirname(os.path.realpath(\"__file__\"))\n",
    "wac2015_filepath = os.path.join(dirname, \"../data/wac/ca_wac_S000_JT00_2015.csv.gz\")\n",
    "wac2002_filepath = os.path.join(dirname, \"../data/wac/ca_wac_S000_JT00_2002.csv.gz\")\n",
    "cxwalk_filepath = os.path.join(dirname, \"../data/wac/ca_xwalk.csv.gz\")\n",
    "tracts_shp_filepath = os.path.join(dirname, \"../data/census_tracts/tracts_2010_4326.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load 2002 & 2015 census wac data, plus crosswalk file\n",
    "wac2015 = pd.read_csv(wac2015_filepath, sep=\",\", delimiter=None, header=\"infer\", names=None, index_col=None, usecols=None, compression=\"gzip\")\n",
    "wac2002 = pd.read_csv(wac2002_filepath, sep=\",\", delimiter=None, header=\"infer\", names=None, index_col=None, usecols=None, compression=\"gzip\")\n",
    "xwalk = pd.read_csv(cxwalk_filepath, sep=\",\", delimiter=None, header=\"infer\", names=None, index_col=None, usecols=None, compression=\"gzip\", encoding=\"ISO-8859-1\", low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter and Rollup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter crosswalk table by 9 counties of SF Bay Area\n",
    "cty_fips_list = [6001, 6013, 6041, 6055, 6075, 6081, 6085, 6095, 6097]\n",
    "cxwalk = cxwalk[cxwalk['cty'].isin(cty_fips_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the block and tract id columns\n",
    "cxwalk = cxwalk[['tabblk2010', 'trct']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join 2015 and 2002 wac files to cxwalk using fields w_geocode and tabblk2010\n",
    "wac2015 = wac2015.merge(cxwalk, how=\"inner\", left_on=\"w_geocode\", right_on=\"tabblk2010\")\n",
    "wac2002 = wac2002.merge(cxwalk, how=\"inner\", left_on=\"w_geocode\", right_on=\"tabblk2010\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAICS codes for each super category\n",
    "makers = ['CNS01', 'CNS02', 'CNS03', 'CNS04', 'CNS05', 'CNS06', 'CNS08']\n",
    "services = ['CNS07', 'CNS14', 'CNS17', 'CNS18']\n",
    "professions = ['CNS09', 'CNS10', 'CNS11', 'CNS12', 'CNS13']\n",
    "support = ['CNS15', 'CNS16', 'CNS19', 'CNS20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new aggregate columns for various job sectors\n",
    "wac2015['makers'] = wac2015[makers].sum(axis=1)\n",
    "wac2015['services'] = wac2015[services].sum(axis=1)\n",
    "wac2015['professions'] = wac2015[professions].sum(axis=1)\n",
    "wac2015['support'] = wac2015[support].sum(axis=1)\n",
    "wac2015['total'] = wac2015['C000']\n",
    "\n",
    "wac2002['makers'] = wac2002[makers].sum(axis=1)\n",
    "wac2002['services'] = wac2002[services].sum(axis=1)\n",
    "wac2002['professions'] = wac2002[professions].sum(axis=1)\n",
    "wac2002['support'] = wac2002[support].sum(axis=1)\n",
    "wac2002['total'] = wac2002['C000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure things add up\n",
    "assert sum(wac2015['C000'] -(wac2015['makers'] + wac2015['services'] + wac2015['professions'] + wac2015['support'])) == 0\n",
    "assert sum(wac2002['C000'] -(wac2002['makers'] + wac2002['services'] + wac2002['professions'] + wac2002['support'])) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the columns we need from the wac dataframe\n",
    "to_keep = ['trct', 'makers', 'services', 'professions', 'support', 'total']\n",
    "wac2015 = wac2015[to_keep]\n",
    "wac2002 = wac2002[to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group and aggregate data by census tract\n",
    "wac2015 = wac2015.groupby('trct', as_index=False).agg(np.sum)\n",
    "wac2002 = wac2002.groupby('trct', as_index=False).agg(np.sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LQ Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store totals for each category, these will be the total jobs by category for the entire bay area\n",
    "makers_total_2015 = wac2015['makers'].sum()\n",
    "services_total_2015 = wac2015['services'].sum()\n",
    "professions_total_2015 = wac2015['professions'].sum()\n",
    "support_total_2015 = wac2015['support'].sum()\n",
    "all_total_2015 = wac2015['total'].sum()\n",
    "\n",
    "makers_total_2002 = wac2002['makers'].sum()\n",
    "services_total_2002 = wac2002['services'].sum()\n",
    "professions_total_2002 = wac2002['professions'].sum()\n",
    "support_total_2002 = wac2002['support'].sum()\n",
    "all_total_2002 = wac2002['total'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate percentages for each category, these will be used for determining the location quotients later\n",
    "makers_pct_2015 = makers_total_2015 / all_total_2015\n",
    "services_pct_2015 = services_total_2015 / all_total_2015\n",
    "professions_pct_2015 = professions_total_2015 / all_total_2015\n",
    "support_pct_2015 = support_total_2015 / all_total_2015\n",
    "\n",
    "makers_pct_2002 = makers_total_2002 / all_total_2002\n",
    "services_pct_2002 = services_total_2002 / all_total_2002\n",
    "professions_pct_2002 = professions_total_2002 / all_total_2002\n",
    "support_pct_2002 = support_total_2002 / all_total_2002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "wac_all = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute tract level location quotients\n",
    "wac_all['make_lq2015'] = wac2015['makers'] / wac2015['total'] / makers_pct_2015\n",
    "wac_all['serv_lq2015'] = wac2015['services'] / wac2015['total'] / services_pct_2015\n",
    "wac_all['prof_lq2015'] = wac2015['professions'] / wac2015['total'] / professions_pct_2015\n",
    "wac_all['supp_lq2015'] = wac2015['support'] / wac2015['total'] / support_pct_2015\n",
    "\n",
    "wac_all['make_lq2002'] = wac2002['makers'] / wac2002['total'] / makers_pct_2002\n",
    "wac_all['serv_lq2002'] = wac2002['services'] / wac2002['total'] / services_pct_2002\n",
    "wac_all['prof_lq2002'] = wac2002['professions'] / wac2002['total'] / professions_pct_2002\n",
    "wac_all['supp_lq2002'] = wac2002['support'] / wac2002['total'] / support_pct_2002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the lq difference from 2002 – 2015\n",
    "wac_all['make_change'] = wac_all['make_lq2015'] - wac_all['make_lq2002']\n",
    "wac_all['serv_change'] = wac_all['serv_lq2015'] - wac_all['serv_lq2002']\n",
    "wac_all['prof_change'] = wac_all['prof_lq2015'] - wac_all['prof_lq2002']\n",
    "wac_all['supp_change'] = wac_all['supp_lq2015'] - wac_all['supp_lq2002']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to keep for output csv\n",
    "columns = ['make_lq2015', 'make_lq2002', 'make_change', 'serv_lq2015', 'serv_lq2002', 'serv_change', 'prof_lq2015', 'prof_lq2002', 'prof_change', 'supp_lq2015', 'supp_lq2002', 'supp_change']\n",
    "outfile = os.path.join(dirname, 'wac_lq_change_2002_2015.csv')\n",
    "wac_all.to_csv(outfile, columns=columns, index=False, encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
